---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD student at the [Institute of Information Engineering](http://www.iie.ac.cn/), [Chinese Academy of Sciences (CAS)](https://www.cas.cn/), specializing in the research of large language models (LLMs). I am expected to graduate in July 2025.

My research focuses on model compression and acceleration, specifically in the context of LLMs. I am interested in utilizing techniques like quantization, knowledge distillation, and pruning to improve computational efficiency and performance of LLMs. My ultimate goal is to achieve efficient language models.


# üî• News
- *2024.03.30*: &nbsp;üéâüéâ Feeling tired and sleepy, it's time for a relaxing moment. ‚òû[FunAI](https://funai.vip)


## üìù Selected Papers [[Full List](https://xyangyan.github.io/publications/)] [[Google Scholar](https://scholar.google.com/citations?user=gDJkRzwAAAAJ&hl)] 

* A Contrastive Self-distillation BERT with Kernel Alignment-Based Inference <br>
<i>International Conference on Computational Science </i> (**ICCS**), 2023. **IIE-B Conference** <br>
[**pdf**](https://www.researchgate.net/publication/372006456_A_Contrastive_Self-distillation_BERT_with_Kernel_Alignment-Based_Inference) | [**code**](https://github.com/xyangyan/CsdBERT)

* MetaBERT: Collaborative Meta-Learning for Accelerating BERT Inference <br>
<i>International Conference on Computer Supported Cooperative Work in Design </i> (**CSCWD**), 2023. **CCF-C Conference** <br>
[**pdf**](https://www.researchgate.net/publication/371825485_MetaBERT_Collaborative_Meta-Learning_for_Accelerating_BERT_Inference) | [**code**](https://github.com/xyangyan/MetaBERT)


## üéñ Honors and Awards
* PhD Graduate Study Scholarship First Prize, UCAS, 2022.
* Merit Student, UCAS, 2022~2023.
* Merit Student, UCAS, 2021~2022.

## üìñ Teaching
* Machine Learning, Teaching Assistant, UCAS.
* Pattern Matching and Information Filtering, Teaching Assistant, UCAS.

## Academic Service
* Reviewers of Conferences: ICASSP 2024.
